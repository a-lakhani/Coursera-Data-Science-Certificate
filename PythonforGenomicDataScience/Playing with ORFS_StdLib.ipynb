{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from collections.abc import Sequence\n",
    "from pprint import pprint\n",
    "\n",
    "path_to_fasta_file = '/home/alakhani/Coursera-Projects/PythonforGenomicDataScience/FASTA_Files/dna.example_copy.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTA record descriptions begin with '>', \n",
    "# Simplest way of counting without doing anything else:\n",
    "\n",
    "with open(path_to_fasta_file,'r') as fasta_file:\n",
    "    count = fasta_file.read().count('>')\n",
    "\n",
    "# print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary comprehension directly from file looks cool but\n",
    "# does not seem amenable for collecting sequence values in the same iteration.\n",
    "\n",
    "with open(path_to_fasta_file,'r') as fasta_file:\n",
    "    seq_dict = {line.strip('>\\n'): None for line in fasta_file \n",
    "                if line[0] == \">\"}\n",
    "    \n",
    "# print('Length of dictionary made \"the python way\"', len(seq_dict_2),'\\n')\n",
    "# pprint(seq_dict.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8d3a4",
   "metadata": {},
   "source": [
    "## Collecting sequences from a FASTA file into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dac184",
   "metadata": {},
   "source": [
    "### The more familiar, \"less pythonic\" way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405e184",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fasta_todict(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        header = \"\"\n",
    "        seq_accumulator = []\n",
    "        sequences = {}\n",
    "        for line in fasta_file:\n",
    "            # For first line/header.\n",
    "            if line[0] == \">\" and not (header or seq_accumulator):     \n",
    "                header = line.strip('>\\n')\n",
    "            elif line[0] == \">\" and seq_accumulator:\n",
    "                sequences[header] = ''.join(seq_accumulator)\n",
    "                seq_accumulator.clear()\n",
    "                header = line.strip('>\\n')\n",
    "            elif header:\n",
    "                seq_accumulator.append(line.strip())\n",
    "            else:\n",
    "                print(\"Check file.\"\n",
    "                    \"Missing header on first line or two consecutive headers.\")\n",
    "        # Loop ends before the last sequence is paired with header.\n",
    "        sequences[header] = ''.join(seq_accumulator)\n",
    "        return sequences\n",
    "\n",
    "# seqs = fasta_todict(path_to_fasta_file)    \n",
    "# print('Length of sequence dictionary\"', len(sequences))\n",
    "# print(sequences)\n",
    "# partial_list = [item[1] for item in enumerate(seqs.items()) if item[0] < 4]\n",
    "# z = iter(seqs.items())\n",
    "# partial_list = [next(z) for _ in range(4)]\n",
    "# print(list(seqs.items())[:4])\n",
    "# print(partial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d924b2b",
   "metadata": {},
   "source": [
    "## That was clunky. Is there a cleaner way with itertools?\n",
    "\n",
    "Iterators save memory with 'lazy execution', i.e. they don't start doing the thing until you ask them.\n",
    "This will let us directly feed keys and values into a dictionary without reading into a list first.  \\*\\*\\*\\*\n",
    "\n",
    "We can use a key function to tell `groupby()` to split the file into chunks of consecutive lines that either do or do not start with '>'.\n",
    "`groupby()` returns tuples of `(bool, _grouper)`. `__grouper` is not the sequence chunk, it is itself an iterator that \"knows\" to go through the file and collect lines into chunks, when or if we ask.\n",
    "\n",
    "We need to iterate through (call `__next__` on) the second item in each tuple to tell `__grouper` to actually start iterating through the file and retrieve the next chunk of lines.\n",
    "\n",
    "Calling `next()` retrieves and 'expends' the next value(s) in an iterator (same thing a for loop does), so if `next()` is used in a loop those values or 'positions in the list' will get 'skipped' in the next loop.\n",
    "\n",
    "\\*\\*\\*\\* This was my mistake! Groupby is more memory efficient than reading in the whole file at once and then making a second temporary list. But groupby is still constructing a temporary list of lines for each chunk under the hood, then we're iterating over those temporary lists to join lines. I.e., the same thing we did above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11c73a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joinlines(iterable):\n",
    "    return ''.join(line.strip() for line in iterable)\n",
    "\n",
    "def fasta_todict2(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        if fasta_file.readline()[0] != '>':\n",
    "            print(\"File needs to start with header preceded by '>'.\") \n",
    "        else:\n",
    "            fasta_file.seek(0)\n",
    "            chunks = itertools.groupby(fasta_file, key=lambda x: x[0]=='>')\n",
    "            seqdict = {joinlines(chunk[1]).strip('>'): \n",
    "                       joinlines(next(chunks)[1]) for chunk in chunks}\n",
    "            return seqdict\n",
    "\n",
    "# seqdict = fasta_todict2(path_to_fasta_file)\n",
    "\n",
    "# print(list(seqdict.items())[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to next(), we can zip an iterator with itself.\n",
    "# This will also 'expend' multiple values in one iteration over the zip object.\n",
    "# Note: zip() in Python 3 behaves the same as itertools.izip(). \n",
    "#       zip() in Python 2 returns the entire list at once.  \n",
    "# Also, zipping with the iterator lead to unexpected behavior with the headers \n",
    "# being dropped. Had to turn chunks into a generator to work as expected.\n",
    "#\n",
    "# Zipping is unnecessary for this application since \n",
    "# we're generating tuples just to unpack them.\n",
    "\n",
    "\n",
    "def fasta_todict3(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        if fasta_file.readline()[0] != '>':\n",
    "            print(\"File needs to start with header preceded by '>'.\") \n",
    "        else:\n",
    "            fasta_file.seek(0)\n",
    "            chunks = (joinlines(chunk[1]).strip('>') for chunk in \n",
    "                      itertools.groupby(fasta_file, key=lambda x: x[0]=='>'))\n",
    "            seqdict = {chunk1: chunk2 for chunk1, chunk2 in zip(chunks,chunks)}\n",
    "            return seqdict\n",
    "\n",
    "# seqs = fasta_todict3(path_to_fasta_file)\n",
    "\n",
    "# print(list(seqs.items())[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc2cbb",
   "metadata": {},
   "source": [
    "### **Proof that all three methods yield equivalent dictionaries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159550",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs1 = fasta_todict(path_to_fasta_file)\n",
    "seqs2 = fasta_todict2(path_to_fasta_file)\n",
    "seqs3 = fasta_todict3(path_to_fasta_file)\n",
    "\n",
    "seqs1 == seqs2 == seqs3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e025ca8",
   "metadata": {},
   "source": [
    "### **Did that optimization make any difference for this 59 kb file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "timeit(\"seqs1 = fasta_todict(path_to_fasta_file)\", \n",
    "       \"path_to_fasta_file = '/home/alakhani/Coursera-Projects/PythonforGenomicDataScience/FASTA_Files/dna.example_copy.fasta'\\n\"\n",
    "\"\"\"def fasta_todict(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        header = \"\"\n",
    "        seq_accumulator = []\n",
    "        sequences = {}\n",
    "        for line in fasta_file:\n",
    "            # For first line/header.\n",
    "            if line[0] == \">\" and not (header or seq_accumulator):\n",
    "                header = line.strip()\n",
    "            elif line[0] == \">\" and seq_accumulator:\n",
    "                sequences[header] = ''.join(seq_accumulator)\n",
    "                seq_accumulator.clear()\n",
    "                header = line.strip()\n",
    "            elif header:\n",
    "                seq_accumulator.append(line.strip())\n",
    "            else:\n",
    "                print(\"Check file.\")\n",
    "        # Loop ends before the last sequence is paired with header.\n",
    "        sequences[header] = ''.join(seq_accumulator)\n",
    "        return sequences\"\"\",\n",
    "        number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f53306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "timeit(\"seqs2 = fasta_todict2(path_to_fasta_file)\", \n",
    "       \"path_to_fasta_file = '/home/alakhani/Coursera-Projects/PythonforGenomicDataScience/FASTA_Files/dna.example_copy.fasta'\\n\"\n",
    "\"\"\"def joinlines(iterable):\n",
    "    return ''.join(line.strip() for line in iterable)\n",
    "def fasta_todict2(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        if fasta_file.readline()[0] != '>':\n",
    "            print(\"File needs to start with header preceded by '>'.\") \n",
    "        else:\n",
    "            fasta_file.seek(0)\n",
    "            chunks = itertools.groupby(fasta_file, key=lambda x: x[0]=='>')\n",
    "            seqdict = {joinlines(chunk[1]): joinlines(next(chunks)[1]) for \n",
    "                       chunk in chunks}\n",
    "            return seqdict\"\"\",\n",
    "        number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "\n",
    "timeit(\"seqs3 = fasta_todict3(path_to_fasta_file)\", \n",
    "       \"path_to_fasta_file = '/home/alakhani/Coursera-Projects/PythonforGenomicDataScience/FASTA_Files/dna.example_copy.fasta'\\n\"\n",
    "\"\"\"def joinlines(iterable):\n",
    "    return ''.join(line.strip() for line in iterable)\n",
    "def fasta_todict3(filepath):\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        if fasta_file.readline()[0] != '>':\n",
    "            print(\"File needs to start with header preceded by '>'.\") \n",
    "        else:\n",
    "            fasta_file.seek(0)\n",
    "            chunks = (joinlines(chunk[1]) for chunk in \n",
    "                      itertools.groupby(fasta_file, key=lambda x: x[0]=='>'))\n",
    "            seqdict = {chunk1: chunk2 for chunk1, chunk2 in zip(chunks,chunks)}\n",
    "            return seqdict\"\"\",\n",
    "        number=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b80a27",
   "metadata": {},
   "source": [
    "## Lol\n",
    "Indeed, all that glitters is not gold. The 'dumb way' was faster and will be more readable (to me) in 6 months.\n",
    "\n",
    "It seems the extra overhead from creating extra intermediate objects to perform disjointed nested loops, plus calling a lambda function on each line instead of a simple conditional outweighed the idea that \"it's faster because it's implemented in C\".\n",
    "\n",
    "To be fair, these tools seem more oriented towards managing memory consumption, which is contradicted by copying everything into a dictionary anyway. \n",
    "If we truly needed to avoid copying data unless or until it was needed, it could make more sense to save the `__grouper` objects as dictionary values. However, since the philosophy of Python is to abstract away these types of concerns, maybe it would be unnecessary even then.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932ef7f",
   "metadata": {},
   "source": [
    "## Let's play with dictionaries some more\n",
    "\n",
    "First we'll define `fasta_to_nesteddict` to create a nested dict, so we can associate additional properties with each sequence name.\n",
    "\n",
    "Then we'll pretend we already have a flat dictionary and can't or don't want to create a copycat function. In this case we need to replace dictionary values with a nested dictionary, while retaining the original dictionary value somewhere. \n",
    "\n",
    "#### This highlights one of the advantages of implementing a class rather than a dictionary. What if we want to say, store a property of a property? Class implementation will be explored later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_nesteddict(filepath):\n",
    "    '''Returns {$FASTA_HEADER: {'Sequence': $SEQUENCE}}'''\n",
    "    with open(filepath,'r') as fasta_file:\n",
    "        header = \"\"\n",
    "        seq_accumulator = []\n",
    "        sequences = {}\n",
    "        for line in fasta_file:\n",
    "            # For first line/header.\n",
    "            if line[0] == \">\" and not (header or seq_accumulator):     \n",
    "                header = line.strip('>\\n')\n",
    "            elif line[0] == \">\" and seq_accumulator:\n",
    "                sequences[header] = {'Sequence': ''.join(seq_accumulator)}\n",
    "                seq_accumulator.clear()\n",
    "                header = line.strip('>\\n')\n",
    "            elif header:\n",
    "                seq_accumulator.append(line.strip())\n",
    "            else:\n",
    "                print(\"Check file.\"\n",
    "                    \"Missing header on first line or two consecutive headers.\")\n",
    "        # Loop ends before the last sequence is paired with header.\n",
    "        sequences[header] = {'Sequence': ''.join(seq_accumulator)}\n",
    "        return sequences\n",
    "    \n",
    "# nestedseqdict = fasta_to_nesteddict(path_to_fasta_file)\n",
    "# nestedseqdict_items = iter(nestedseqdict.items())\n",
    "# print([next(nestedseqdict_items) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e13a4",
   "metadata": {},
   "source": [
    "## Adding another level of hierarchy to a flat dictionary \n",
    "\n",
    "In the next function, two parameters are given default values of None, when the intended behavior is to have these parameters default to empty lists. \n",
    "\n",
    "This is due to Python's treatment of mutable default arguments:\n",
    "\n",
    "> <https://stackoverflow.com/questions/1132941/least-astonishment-and-the-mutable-default-argument>\n",
    "\n",
    "> <https://docs.python-guide.org/writing/gotchas/#mutable-default-arguments>\n",
    "\n",
    "When functions are defined with default values in Python, objects are initialized with these default values. These default argument *objects*, not the defined default *values*, \"stick with\" the function object throughout the program. \n",
    "\n",
    "If an argument with a mutable default is mutated within a function, calling the function without explicitly declaring this argument will change the argument's \"default value\" for future function calls.\n",
    "This implies a defensive programming practice of explicitly defining mutable arguments if we intend them to be empty.\n",
    "\n",
    "In the function below we do not mutate addkeys or addvals, but it is advisable to avoid mutable defaults as a rule unless this state dependence is specifically intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function requires that addvals support indexing.\n",
    "\n",
    "def nestdict(currentdict, newvalname=\"Old val\", addkeys=None, \n",
    "             addvals: Sequence=None):\n",
    "    '''Replaces dict values with {newvalname: currentdict[key]}. \n",
    "\n",
    "    New key:val pairs can be added to each key's nested dictionary using addkeys and addvals.\n",
    "    Members of addvals can be called on currentdict values.\n",
    "    If addkeys is longer than addvals, unmatched members of addkeys are initialized to None.\n",
    "    Unmatched members of addvals are ignored. \n",
    "    '''\n",
    "    newdict = {}\n",
    "    addkeys = [] if addkeys is None else addkeys\n",
    "    addvals = [] if addvals is None else addvals \n",
    "    for key, val in currentdict.items():\n",
    "        lvl2dict = {}\n",
    "        lvl2dict[newvalname] = val\n",
    "        for index, name in enumerate(addkeys):\n",
    "            try:\n",
    "                x = addvals[index]\n",
    "            except IndexError:\n",
    "                x = None\n",
    "            except:\n",
    "                print(\"addvals in nestdict must be None or a Sequence.\")\n",
    "                raise\n",
    "            if callable(x):\n",
    "                lvl2dict[name] = x(val)\n",
    "            else:\n",
    "                lvl2dict[name] = x\n",
    "        newdict[key] = lvl2dict\n",
    "    if len(addvals) > index + 1:\n",
    "        print(\"More values than keys provided, excess values ignored.\")\n",
    "    return newdict\n",
    "\n",
    "# z = nestdict(fasta_todict(path_to_fasta_file), 'sequence', ['length','ORFs'], [lambda x: len(x), None])\n",
    "# z_items = iter(z.items())\n",
    "# print([next(z_items) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9cde3",
   "metadata": {},
   "source": [
    "**Another approach**\n",
    "\n",
    "`zip_longest()` is cleaner and allows compatibility with iterables that do not support indexing, although the latter seems to have limited benefit. \n",
    "\n",
    "Similar to the previous version, if addvals is longer than addkeys for some reason, key values will default to `None` once addkeys is exhausted.  \n",
    "`zip_longest()` will then generate tuples with the pattern `((None, val_n-2), (None, val_n-1)...(None, val_n))`, each excess value being overwritten until only the last value in addvals is saved.  \n",
    "Managing this will be left to the user. A warning cannot be based on `len` in this case because at no point is there a guarantee that addvals supports `len`.  \n",
    "\n",
    "\\#whenthedocstringisaslongasthefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestdict(currentdict, newvalname=\"Old val\", addkeys=None, addvals=None):\n",
    "    '''Replaces dict values with {newvalname: currentdict[key]}. \n",
    "\n",
    "    addkeys and addvals are zipped to generate new key:val pairs for each key's nested dictionary. \n",
    "    Members of addvals can be called on currentdict values.\n",
    "    If addkeys is longer than addvals, unmatched members of addkeys are initialized to None.\n",
    "    If addvals is longer than addkeys, unmatched members of addvals will be lost except for the last element. The last members of the nested dicts will be (None: addvals[n]).\n",
    "    '''\n",
    "    newdict = {}\n",
    "    addkeys = [] if addkeys is None else addkeys\n",
    "    addvals = [] if addvals is None else addvals\n",
    "    for key, val in currentdict.items():\n",
    "        lvl2dict = {}\n",
    "        lvl2dict[newvalname] = val\n",
    "        lvl2dict.update((k, v(val)) if callable(v) else (k, v)\n",
    "                        for k, v in \n",
    "                        itertools.zip_longest(addkeys, addvals))\n",
    "        newdict[key] = lvl2dict\n",
    "    return newdict\n",
    "\n",
    "# z = nestdict(fasta_todict(path_to_fasta_file), 'sequence', ['length','ORFs', 'more', 'keys'], {'dictionary': 'inception', 'this':'is', 'why':'classes', 'are':'probably', 'better': None}.items())\n",
    "# z_items = iter(z.items())\n",
    "# print([next(z_items) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqdict = fasta_todict(path_to_fasta_file)\n",
    "nestedseqdict = fasta_to_nesteddict(path_to_fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e078c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [i for i in seqdict.values()]\n",
    "n = [i['Sequence'] for i in nestedseqdict.values()]\n",
    "s == n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3c385",
   "metadata": {},
   "source": [
    "### Well now what if we want to add more values to the nested dictionaries? <sup><sup><sup>or add values to nested nested dictionaries?</sup></sup></sup>\n",
    "\n",
    "\\#needasequenceclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-oriented, modifies dictionary directly.\n",
    "\n",
    "def update_ndicts_inplace(currentdict, addkeys=None, addvals=None, modkey=''):\n",
    "    '''Members of addvals can optionally be called on nesteddict[modkey].\n",
    "    Uses zip_longest(addkeys, addvals).\n",
    "    '''\n",
    "    addkeys = [] if addkeys is None else addkeys\n",
    "    addvals = [] if addvals is None else addvals\n",
    "    if modkey:\n",
    "        for key, ndict in currentdict.items():\n",
    "            ndict.update((k, v(ndict[modkey])) if callable(v) \n",
    "                        else (k, v) \n",
    "                        for k, v in itertools.zip_longest(addkeys, addvals))\n",
    "    else:\n",
    "        for key, ndict in currentdict.items():\n",
    "            ndict.update((k, v) \n",
    "                        for k, v in itertools.zip_longest(addkeys, addvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure function, returns a new dictionary without modifying the original.\n",
    "from copy import deepcopy\n",
    "\n",
    "def updated_ndict(currentdict, addkeys=None, addvals=None, modkey=''):\n",
    "    '''Members of addvals can be called on nesteddict[modkey].\n",
    "    Uses zip_longest(addkeys, addvals).\n",
    "    '''\n",
    "    addkeys = [] if addkeys is None else addkeys\n",
    "    addvals = [] if addvals is None else addvals\n",
    "    dictcopy = deepcopy(currentdict)\n",
    "    if modkey:\n",
    "        for key, ndict in dictcopy.items():\n",
    "            ndict.update((k, v(ndict[modkey])) if callable(v) \n",
    "                         else (k, v) \n",
    "                         for k, v in itertools.zip_longest(addkeys, addvals))\n",
    "    else:\n",
    "        for key, ndict in dictcopy.items():\n",
    "            ndict.update((k, v) \n",
    "                        for k, v in itertools.zip_longest(addkeys, addvals))\n",
    "    return dictcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c215212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1496728fd4910581be769dbea2647f5ee73a9be9d1697e51a4ff491ad13ee4c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('working': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
